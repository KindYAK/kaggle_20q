{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generating samples of game state with GPT-4o\n",
    "# Instead of simulating every step, we ask GPT to generate a probable game state,\n",
    "# given that guesser is very smart and eventually wins\n",
    "\n",
    "import asyncio\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%autoreload now\n",
    "import logging\n",
    "\n",
    "from data_collection.generate_snapshot import generate_snapshot\n",
    "from data_collection.semaphore import set_semaphore\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "set_semaphore(\"gpt-4\", 100)",
   "id": "8853b544b39c772",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "client = AsyncOpenAI()",
   "id": "6b07c50e4cb7642e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# {\n",
    "#         \"things\": 100,\n",
    "#         \"city\": 40,\n",
    "#         \"country\": 20,\n",
    "#         \"landmark\": 40,\n",
    "#     }"
   ],
   "id": "e2c58c2a0eb6da69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "keywords_by_category = pickle.load(open(\"../keywords_by_category.pkl\", \"rb\"))\n",
    "all_dfs = pd.concat(keywords_by_category.values())\n",
    "keywords_flat = list(all_dfs.keyword)"
   ],
   "id": "dda4b0380a6c9c66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "eb8ce5f7ba83c45a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# generated = await generate_snapshot(client, \"ice tea\")\n",
    "all_generated = await asyncio.gather(*[generate_snapshot(client, keyword) for keyword in keywords_flat])"
   ],
   "id": "3e7a36dd49fb9b0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "total_generated = [generated for generated_list in all_generated for generated in generated_list]",
   "id": "2dfbd024be8e63da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pickle.dump(total_generated, open(\"dataset_17476_from_snapshots.pkl\", \"wb\"))",
   "id": "6ae17247796a9466",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for g in total_generated:\n",
    "    if g['type'] == \"guess_from_snapshot\":\n",
    "        keyword = g['response'].split(\"\\n\")[-1].strip()\n",
    "        prompt_lines = g['prompt'].split(\"\\n\")\n",
    "        # Find indexes of line that contain keyword:\n",
    "        keyword_indexes = [i for i, line in enumerate(prompt_lines) if f\"Your guess: {keyword}\".lower().strip() in line.lower()]\n",
    "        if not keyword_indexes and keyword.endswith(\"s\"):\n",
    "            keyword_indexes = [i for i, line in enumerate(prompt_lines) if f\"Your guess: {keyword[:-1]}\".lower().strip() in line.lower()]\n",
    "        if keyword_indexes:\n",
    "            print(g['prompt'])\n",
    "            print(\"!!!!!!!!\", keyword)\n",
    "        # g['prompt'] = \"\\n\".join([line for i, line in enumerate(prompt_lines) if i not in keyword_indexes])"
   ],
   "id": "3506ae4fcd368d98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for g in total_generated:\n",
    "    if g['type'] == \"questions_candidates_from_snapshot\":\n",
    "        new_response = g['response'].split(\"Question: \")[1].split(\"Answer\")[0].strip()\n",
    "        g['response'] = new_response"
   ],
   "id": "a95e6b2f63bad7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pickle.dump(total_generated, open(\"dataset_17476_from_snapshots_fixed.pkl\", \"wb\"))",
   "id": "e6bb3b6adbd89aa3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2615d3c283b11057",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5963796c10270c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "13452ed037a86d73",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
