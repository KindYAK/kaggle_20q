{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b772a87-43f9-49c2-87cf-bcf578b7e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, get_scheduler\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from utils_simulate import run_games\n",
    "\n",
    "import os\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "HfFolder.save_token(os.environ['HUGGINGFACE_TOKEN'])\n",
    "\n",
    "import datasets\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from transformers.utils import logging\n",
    "# logging.set_verbosity_info()\n",
    "\n",
    "import logging\n",
    "from transformers.utils import logging as transformers_logging\n",
    "\n",
    "class CustomFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return 'right-padding was detected' not in record.getMessage()\n",
    "\n",
    "logger = logging.getLogger('transformers')\n",
    "\n",
    "for handler in logger.handlers:\n",
    "    handler.addFilter(CustomFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0069e6-a5fe-4967-8ccb-7e1402960eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5316a2457024c13ba1e997fc41a349c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# model_id = \"astronomer/Llama-3-8B-Special-Tokens-Adjusted\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side='left')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side='right')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "id_eot = tokenizer.convert_tokens_to_ids([\"<|eot_id|>\"])[0]\n",
    "pad_token_id = tokenizer.convert_tokens_to_ids([\"<|end_of_text|>\"])[0]\n",
    "\n",
    "tokenizer.pad_token_id = pad_token_id\n",
    "model.config.pad_token_id = pad_token_id\n",
    "\n",
    "# tokenizer.pad_token_id = id_eot\n",
    "# model.config.pad_token_id = id_eot\n",
    "\n",
    "# tokenizer.add_special_tokens({\"pad_token\": \"<|padding_token|>\"})\n",
    "# model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3aea87-d472-4091-8223-af6b90675bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c870d3c9-dcfd-4852-9427-cc981d550728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|end_of_text|>', 128001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token, tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35cd6699-d243-403a-86cc-25650250edb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128009, 128001)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_eot, pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bd279f-56d3-48af-a35a-a83fefeda231",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_basic = pickle.load(open(\"data_collection/!final_dataset_11194_basic.pkl\", \"rb\"))\n",
    "d_hints = pickle.load(open(\"data_collection/!final_dataset_6016_with_hints_after_n_step.pkl\", \"rb\"))\n",
    "d_snap = pickle.load(open(\"data_collection/!final_dataset_17476_from_snapshots_fixed.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99f0d0f-7596-46c1-b550-fa991cb14f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, split_ratio=0.05):\n",
    "    random.shuffle(dataset)\n",
    "    split_index = int(len(dataset) * split_ratio)\n",
    "    eval_set = dataset[:split_index]\n",
    "    train_set = dataset[split_index:]\n",
    "    return train_set, eval_set\n",
    "\n",
    "d_basic, d_basic_eval = split_dataset(d_basic)\n",
    "d_hints, d_hints_eval = split_dataset(d_hints)\n",
    "d_snap, d_snap_eval = split_dataset(d_snap)\n",
    "\n",
    "d_eval = d_basic_eval + d_hints_eval + d_snap_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6ecaa5c-2253-4ff0-a397-29ebca4878da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # TODO TEMP!\n",
    "# d_basic = d_basic[:1000]\n",
    "# d_hints = d_hints[:30]\n",
    "# d_snap = d_snap[:30]\n",
    "# d_eval = d_eval[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1bd15-cb7b-4315-99a1-9d042c96dcd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750dbeed-b2eb-4b56-a234-f3d2f7c3ad26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e35085d-eebe-4ca2-94de-62f37a2cb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_data(data):\n",
    "#     prompts = [item['prompt'] for item in data]\n",
    "#     responses = [item['response'] for item in data]\n",
    "#     return datasets.Dataset.from_dict({\"prompt\": prompts, \"response\": responses})\n",
    "\n",
    "\n",
    "from utils import SYSTEM_PROMPT_ASKER, SYSTEM_PROMPT_ANSWERER\n",
    "# def prepare_inputs(chats: list[dict]):\n",
    "#     tokenizer.padding_side = \"left\"\n",
    "#     r_inputs = tokenizer.apply_chat_template(\n",
    "#         [\n",
    "#             [\n",
    "#                 {\"role\": \"system\", \"content\": SYSTEM_PROMPT_ASKER if \"only YES or NO\" not in o['prompt'] else SYSTEM_PROMPT_ANSWERER},\n",
    "#                 {\"role\": \"user\", \"content\": o['prompt']},\n",
    "#             ] for o in chats\n",
    "#         ],\n",
    "#         tokenize=True,\n",
    "#         padding=\"longest\",\n",
    "#         return_dict=True,\n",
    "#     )\n",
    "#     tokenizer.padding_side = \"right\"\n",
    "#     r_labels = tokenizer.apply_chat_template(\n",
    "#         [\n",
    "#             [\n",
    "#                 {\"role\": \"assistant\", \"content\": o['response']}\n",
    "#             ] for o in chats\n",
    "#         ],\n",
    "#         tokenize=True,\n",
    "#         padding=\"longest\",\n",
    "#         # return_dict=True,\n",
    "#     )\n",
    "#     return datasets.Dataset.from_dict(\n",
    "#         {\n",
    "#             \"input_ids\": r_inputs['input_ids'],\n",
    "#             \"attention_mask\": r_inputs['attention_mask'],\n",
    "#             \"labels\": r_labels,\n",
    "#         }\n",
    "#     ).shuffle(seed=42)\n",
    "\n",
    "\n",
    "def prepare_inputs(chats: list[dict]):\n",
    "    r_inputs = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT_ASKER if \"only YES or NO\" not in o['prompt'] else SYSTEM_PROMPT_ANSWERER},\n",
    "                {\"role\": \"user\", \"content\": o['prompt']},                \n",
    "                {\"role\": \"assistant\", \"content\": o['response']}\n",
    "            ] for o in chats\n",
    "        ],\n",
    "        tokenize=False,\n",
    "        padding=False,\n",
    "        return_dict=False,\n",
    "    )\n",
    "    return datasets.Dataset.from_dict(\n",
    "        {\"texts\": [r[:-len(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\")] for r in r_inputs]}\n",
    "    ).shuffle(seed=42)\n",
    "\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "    # return tokenizer(examples['prompt'], text_target=examples['response'], truncation=True, padding=\"max_length\", max_length=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b2066-2cbd-4263-ae99-69870acab1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7385f7f-6d9f-48ba-8376-19384319b3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab18875-5f31-4028-ac9e-181f02c0078d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d12cb-f138-45c1-a43a-dee14e1592c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b0b00c2-6122-422c-8e1b-30bfa3af73a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_basic 7961\n",
      "d_hints 4287\n",
      "ds_snap 16603\n",
      "ds_eval 1517\n"
     ]
    }
   ],
   "source": [
    "ds_basic = prepare_inputs(d_basic)\n",
    "print(\"ds_basic\", len(ds_basic))\n",
    "\n",
    "ds_hints = prepare_inputs(d_hints)\n",
    "print(\"d_hints\", len(d_hints))\n",
    "\n",
    "ds_snap = prepare_inputs(d_snap)\n",
    "print(\"ds_snap\", len(ds_snap))\n",
    "\n",
    "ds_eval = prepare_inputs(d_eval)\n",
    "print(\"ds_eval\", len(ds_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84888f00-96b3-4d4c-ad91-ed8e7c21b937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7180629-d2b0-4865-86ed-16851698266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"model.layers.\" not in name and not \"head\" in name and not \"embed_tokens\" in name:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "    if \"mlp\" in name:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "    if \"norm\" in name:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "    if \"head\" in name or \"embed_tokens\" in name:\n",
    "        continue\n",
    "    layer_num = int(name.split(\".\")[2])\n",
    "    if layer_num <= 21:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"model.layers.\" not in name and not \"head\" in name:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "#     if \"mlp\" in name:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "#     if \"norm\" in name:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "#     if \"head\" in name:\n",
    "#         continue\n",
    "#     layer_num = int(name.split(\".\")[2])\n",
    "#     if layer_num <= 20:\n",
    "#         param.requires_grad = False\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfe71b3a-d359-4340-b5bb-30937f84ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight True\n",
      "model.layers.0.self_attn.q_proj.weight False\n",
      "model.layers.0.self_attn.k_proj.weight False\n",
      "model.layers.0.self_attn.v_proj.weight False\n",
      "model.layers.0.self_attn.o_proj.weight False\n",
      "model.layers.0.mlp.gate_proj.weight False\n",
      "model.layers.0.mlp.up_proj.weight False\n",
      "model.layers.0.mlp.down_proj.weight False\n",
      "model.layers.0.input_layernorm.weight False\n",
      "model.layers.0.post_attention_layernorm.weight False\n",
      "model.layers.1.self_attn.q_proj.weight False\n",
      "model.layers.1.self_attn.k_proj.weight False\n",
      "model.layers.1.self_attn.v_proj.weight False\n",
      "model.layers.1.self_attn.o_proj.weight False\n",
      "model.layers.1.mlp.gate_proj.weight False\n",
      "model.layers.1.mlp.up_proj.weight False\n",
      "model.layers.1.mlp.down_proj.weight False\n",
      "model.layers.1.input_layernorm.weight False\n",
      "model.layers.1.post_attention_layernorm.weight False\n",
      "model.layers.2.self_attn.q_proj.weight False\n",
      "model.layers.2.self_attn.k_proj.weight False\n",
      "model.layers.2.self_attn.v_proj.weight False\n",
      "model.layers.2.self_attn.o_proj.weight False\n",
      "model.layers.2.mlp.gate_proj.weight False\n",
      "model.layers.2.mlp.up_proj.weight False\n",
      "model.layers.2.mlp.down_proj.weight False\n",
      "model.layers.2.input_layernorm.weight False\n",
      "model.layers.2.post_attention_layernorm.weight False\n",
      "model.layers.3.self_attn.q_proj.weight False\n",
      "model.layers.3.self_attn.k_proj.weight False\n",
      "model.layers.3.self_attn.v_proj.weight False\n",
      "model.layers.3.self_attn.o_proj.weight False\n",
      "model.layers.3.mlp.gate_proj.weight False\n",
      "model.layers.3.mlp.up_proj.weight False\n",
      "model.layers.3.mlp.down_proj.weight False\n",
      "model.layers.3.input_layernorm.weight False\n",
      "model.layers.3.post_attention_layernorm.weight False\n",
      "model.layers.4.self_attn.q_proj.weight False\n",
      "model.layers.4.self_attn.k_proj.weight False\n",
      "model.layers.4.self_attn.v_proj.weight False\n",
      "model.layers.4.self_attn.o_proj.weight False\n",
      "model.layers.4.mlp.gate_proj.weight False\n",
      "model.layers.4.mlp.up_proj.weight False\n",
      "model.layers.4.mlp.down_proj.weight False\n",
      "model.layers.4.input_layernorm.weight False\n",
      "model.layers.4.post_attention_layernorm.weight False\n",
      "model.layers.5.self_attn.q_proj.weight False\n",
      "model.layers.5.self_attn.k_proj.weight False\n",
      "model.layers.5.self_attn.v_proj.weight False\n",
      "model.layers.5.self_attn.o_proj.weight False\n",
      "model.layers.5.mlp.gate_proj.weight False\n",
      "model.layers.5.mlp.up_proj.weight False\n",
      "model.layers.5.mlp.down_proj.weight False\n",
      "model.layers.5.input_layernorm.weight False\n",
      "model.layers.5.post_attention_layernorm.weight False\n",
      "model.layers.6.self_attn.q_proj.weight False\n",
      "model.layers.6.self_attn.k_proj.weight False\n",
      "model.layers.6.self_attn.v_proj.weight False\n",
      "model.layers.6.self_attn.o_proj.weight False\n",
      "model.layers.6.mlp.gate_proj.weight False\n",
      "model.layers.6.mlp.up_proj.weight False\n",
      "model.layers.6.mlp.down_proj.weight False\n",
      "model.layers.6.input_layernorm.weight False\n",
      "model.layers.6.post_attention_layernorm.weight False\n",
      "model.layers.7.self_attn.q_proj.weight False\n",
      "model.layers.7.self_attn.k_proj.weight False\n",
      "model.layers.7.self_attn.v_proj.weight False\n",
      "model.layers.7.self_attn.o_proj.weight False\n",
      "model.layers.7.mlp.gate_proj.weight False\n",
      "model.layers.7.mlp.up_proj.weight False\n",
      "model.layers.7.mlp.down_proj.weight False\n",
      "model.layers.7.input_layernorm.weight False\n",
      "model.layers.7.post_attention_layernorm.weight False\n",
      "model.layers.8.self_attn.q_proj.weight False\n",
      "model.layers.8.self_attn.k_proj.weight False\n",
      "model.layers.8.self_attn.v_proj.weight False\n",
      "model.layers.8.self_attn.o_proj.weight False\n",
      "model.layers.8.mlp.gate_proj.weight False\n",
      "model.layers.8.mlp.up_proj.weight False\n",
      "model.layers.8.mlp.down_proj.weight False\n",
      "model.layers.8.input_layernorm.weight False\n",
      "model.layers.8.post_attention_layernorm.weight False\n",
      "model.layers.9.self_attn.q_proj.weight False\n",
      "model.layers.9.self_attn.k_proj.weight False\n",
      "model.layers.9.self_attn.v_proj.weight False\n",
      "model.layers.9.self_attn.o_proj.weight False\n",
      "model.layers.9.mlp.gate_proj.weight False\n",
      "model.layers.9.mlp.up_proj.weight False\n",
      "model.layers.9.mlp.down_proj.weight False\n",
      "model.layers.9.input_layernorm.weight False\n",
      "model.layers.9.post_attention_layernorm.weight False\n",
      "model.layers.10.self_attn.q_proj.weight False\n",
      "model.layers.10.self_attn.k_proj.weight False\n",
      "model.layers.10.self_attn.v_proj.weight False\n",
      "model.layers.10.self_attn.o_proj.weight False\n",
      "model.layers.10.mlp.gate_proj.weight False\n",
      "model.layers.10.mlp.up_proj.weight False\n",
      "model.layers.10.mlp.down_proj.weight False\n",
      "model.layers.10.input_layernorm.weight False\n",
      "model.layers.10.post_attention_layernorm.weight False\n",
      "model.layers.11.self_attn.q_proj.weight False\n",
      "model.layers.11.self_attn.k_proj.weight False\n",
      "model.layers.11.self_attn.v_proj.weight False\n",
      "model.layers.11.self_attn.o_proj.weight False\n",
      "model.layers.11.mlp.gate_proj.weight False\n",
      "model.layers.11.mlp.up_proj.weight False\n",
      "model.layers.11.mlp.down_proj.weight False\n",
      "model.layers.11.input_layernorm.weight False\n",
      "model.layers.11.post_attention_layernorm.weight False\n",
      "model.layers.12.self_attn.q_proj.weight False\n",
      "model.layers.12.self_attn.k_proj.weight False\n",
      "model.layers.12.self_attn.v_proj.weight False\n",
      "model.layers.12.self_attn.o_proj.weight False\n",
      "model.layers.12.mlp.gate_proj.weight False\n",
      "model.layers.12.mlp.up_proj.weight False\n",
      "model.layers.12.mlp.down_proj.weight False\n",
      "model.layers.12.input_layernorm.weight False\n",
      "model.layers.12.post_attention_layernorm.weight False\n",
      "model.layers.13.self_attn.q_proj.weight False\n",
      "model.layers.13.self_attn.k_proj.weight False\n",
      "model.layers.13.self_attn.v_proj.weight False\n",
      "model.layers.13.self_attn.o_proj.weight False\n",
      "model.layers.13.mlp.gate_proj.weight False\n",
      "model.layers.13.mlp.up_proj.weight False\n",
      "model.layers.13.mlp.down_proj.weight False\n",
      "model.layers.13.input_layernorm.weight False\n",
      "model.layers.13.post_attention_layernorm.weight False\n",
      "model.layers.14.self_attn.q_proj.weight False\n",
      "model.layers.14.self_attn.k_proj.weight False\n",
      "model.layers.14.self_attn.v_proj.weight False\n",
      "model.layers.14.self_attn.o_proj.weight False\n",
      "model.layers.14.mlp.gate_proj.weight False\n",
      "model.layers.14.mlp.up_proj.weight False\n",
      "model.layers.14.mlp.down_proj.weight False\n",
      "model.layers.14.input_layernorm.weight False\n",
      "model.layers.14.post_attention_layernorm.weight False\n",
      "model.layers.15.self_attn.q_proj.weight False\n",
      "model.layers.15.self_attn.k_proj.weight False\n",
      "model.layers.15.self_attn.v_proj.weight False\n",
      "model.layers.15.self_attn.o_proj.weight False\n",
      "model.layers.15.mlp.gate_proj.weight False\n",
      "model.layers.15.mlp.up_proj.weight False\n",
      "model.layers.15.mlp.down_proj.weight False\n",
      "model.layers.15.input_layernorm.weight False\n",
      "model.layers.15.post_attention_layernorm.weight False\n",
      "model.layers.16.self_attn.q_proj.weight False\n",
      "model.layers.16.self_attn.k_proj.weight False\n",
      "model.layers.16.self_attn.v_proj.weight False\n",
      "model.layers.16.self_attn.o_proj.weight False\n",
      "model.layers.16.mlp.gate_proj.weight False\n",
      "model.layers.16.mlp.up_proj.weight False\n",
      "model.layers.16.mlp.down_proj.weight False\n",
      "model.layers.16.input_layernorm.weight False\n",
      "model.layers.16.post_attention_layernorm.weight False\n",
      "model.layers.17.self_attn.q_proj.weight False\n",
      "model.layers.17.self_attn.k_proj.weight False\n",
      "model.layers.17.self_attn.v_proj.weight False\n",
      "model.layers.17.self_attn.o_proj.weight False\n",
      "model.layers.17.mlp.gate_proj.weight False\n",
      "model.layers.17.mlp.up_proj.weight False\n",
      "model.layers.17.mlp.down_proj.weight False\n",
      "model.layers.17.input_layernorm.weight False\n",
      "model.layers.17.post_attention_layernorm.weight False\n",
      "model.layers.18.self_attn.q_proj.weight False\n",
      "model.layers.18.self_attn.k_proj.weight False\n",
      "model.layers.18.self_attn.v_proj.weight False\n",
      "model.layers.18.self_attn.o_proj.weight False\n",
      "model.layers.18.mlp.gate_proj.weight False\n",
      "model.layers.18.mlp.up_proj.weight False\n",
      "model.layers.18.mlp.down_proj.weight False\n",
      "model.layers.18.input_layernorm.weight False\n",
      "model.layers.18.post_attention_layernorm.weight False\n",
      "model.layers.19.self_attn.q_proj.weight False\n",
      "model.layers.19.self_attn.k_proj.weight False\n",
      "model.layers.19.self_attn.v_proj.weight False\n",
      "model.layers.19.self_attn.o_proj.weight False\n",
      "model.layers.19.mlp.gate_proj.weight False\n",
      "model.layers.19.mlp.up_proj.weight False\n",
      "model.layers.19.mlp.down_proj.weight False\n",
      "model.layers.19.input_layernorm.weight False\n",
      "model.layers.19.post_attention_layernorm.weight False\n",
      "model.layers.20.self_attn.q_proj.weight False\n",
      "model.layers.20.self_attn.k_proj.weight False\n",
      "model.layers.20.self_attn.v_proj.weight False\n",
      "model.layers.20.self_attn.o_proj.weight False\n",
      "model.layers.20.mlp.gate_proj.weight False\n",
      "model.layers.20.mlp.up_proj.weight False\n",
      "model.layers.20.mlp.down_proj.weight False\n",
      "model.layers.20.input_layernorm.weight False\n",
      "model.layers.20.post_attention_layernorm.weight False\n",
      "model.layers.21.self_attn.q_proj.weight False\n",
      "model.layers.21.self_attn.k_proj.weight False\n",
      "model.layers.21.self_attn.v_proj.weight False\n",
      "model.layers.21.self_attn.o_proj.weight False\n",
      "model.layers.21.mlp.gate_proj.weight False\n",
      "model.layers.21.mlp.up_proj.weight False\n",
      "model.layers.21.mlp.down_proj.weight False\n",
      "model.layers.21.input_layernorm.weight False\n",
      "model.layers.21.post_attention_layernorm.weight False\n",
      "model.layers.22.self_attn.q_proj.weight True\n",
      "model.layers.22.self_attn.k_proj.weight True\n",
      "model.layers.22.self_attn.v_proj.weight True\n",
      "model.layers.22.self_attn.o_proj.weight True\n",
      "model.layers.22.mlp.gate_proj.weight False\n",
      "model.layers.22.mlp.up_proj.weight False\n",
      "model.layers.22.mlp.down_proj.weight False\n",
      "model.layers.22.input_layernorm.weight False\n",
      "model.layers.22.post_attention_layernorm.weight False\n",
      "model.layers.23.self_attn.q_proj.weight True\n",
      "model.layers.23.self_attn.k_proj.weight True\n",
      "model.layers.23.self_attn.v_proj.weight True\n",
      "model.layers.23.self_attn.o_proj.weight True\n",
      "model.layers.23.mlp.gate_proj.weight False\n",
      "model.layers.23.mlp.up_proj.weight False\n",
      "model.layers.23.mlp.down_proj.weight False\n",
      "model.layers.23.input_layernorm.weight False\n",
      "model.layers.23.post_attention_layernorm.weight False\n",
      "model.layers.24.self_attn.q_proj.weight True\n",
      "model.layers.24.self_attn.k_proj.weight True\n",
      "model.layers.24.self_attn.v_proj.weight True\n",
      "model.layers.24.self_attn.o_proj.weight True\n",
      "model.layers.24.mlp.gate_proj.weight False\n",
      "model.layers.24.mlp.up_proj.weight False\n",
      "model.layers.24.mlp.down_proj.weight False\n",
      "model.layers.24.input_layernorm.weight False\n",
      "model.layers.24.post_attention_layernorm.weight False\n",
      "model.layers.25.self_attn.q_proj.weight True\n",
      "model.layers.25.self_attn.k_proj.weight True\n",
      "model.layers.25.self_attn.v_proj.weight True\n",
      "model.layers.25.self_attn.o_proj.weight True\n",
      "model.layers.25.mlp.gate_proj.weight False\n",
      "model.layers.25.mlp.up_proj.weight False\n",
      "model.layers.25.mlp.down_proj.weight False\n",
      "model.layers.25.input_layernorm.weight False\n",
      "model.layers.25.post_attention_layernorm.weight False\n",
      "model.layers.26.self_attn.q_proj.weight True\n",
      "model.layers.26.self_attn.k_proj.weight True\n",
      "model.layers.26.self_attn.v_proj.weight True\n",
      "model.layers.26.self_attn.o_proj.weight True\n",
      "model.layers.26.mlp.gate_proj.weight False\n",
      "model.layers.26.mlp.up_proj.weight False\n",
      "model.layers.26.mlp.down_proj.weight False\n",
      "model.layers.26.input_layernorm.weight False\n",
      "model.layers.26.post_attention_layernorm.weight False\n",
      "model.layers.27.self_attn.q_proj.weight True\n",
      "model.layers.27.self_attn.k_proj.weight True\n",
      "model.layers.27.self_attn.v_proj.weight True\n",
      "model.layers.27.self_attn.o_proj.weight True\n",
      "model.layers.27.mlp.gate_proj.weight False\n",
      "model.layers.27.mlp.up_proj.weight False\n",
      "model.layers.27.mlp.down_proj.weight False\n",
      "model.layers.27.input_layernorm.weight False\n",
      "model.layers.27.post_attention_layernorm.weight False\n",
      "model.layers.28.self_attn.q_proj.weight True\n",
      "model.layers.28.self_attn.k_proj.weight True\n",
      "model.layers.28.self_attn.v_proj.weight True\n",
      "model.layers.28.self_attn.o_proj.weight True\n",
      "model.layers.28.mlp.gate_proj.weight False\n",
      "model.layers.28.mlp.up_proj.weight False\n",
      "model.layers.28.mlp.down_proj.weight False\n",
      "model.layers.28.input_layernorm.weight False\n",
      "model.layers.28.post_attention_layernorm.weight False\n",
      "model.layers.29.self_attn.q_proj.weight True\n",
      "model.layers.29.self_attn.k_proj.weight True\n",
      "model.layers.29.self_attn.v_proj.weight True\n",
      "model.layers.29.self_attn.o_proj.weight True\n",
      "model.layers.29.mlp.gate_proj.weight False\n",
      "model.layers.29.mlp.up_proj.weight False\n",
      "model.layers.29.mlp.down_proj.weight False\n",
      "model.layers.29.input_layernorm.weight False\n",
      "model.layers.29.post_attention_layernorm.weight False\n",
      "model.layers.30.self_attn.q_proj.weight True\n",
      "model.layers.30.self_attn.k_proj.weight True\n",
      "model.layers.30.self_attn.v_proj.weight True\n",
      "model.layers.30.self_attn.o_proj.weight True\n",
      "model.layers.30.mlp.gate_proj.weight False\n",
      "model.layers.30.mlp.up_proj.weight False\n",
      "model.layers.30.mlp.down_proj.weight False\n",
      "model.layers.30.input_layernorm.weight False\n",
      "model.layers.30.post_attention_layernorm.weight False\n",
      "model.layers.31.self_attn.q_proj.weight True\n",
      "model.layers.31.self_attn.k_proj.weight True\n",
      "model.layers.31.self_attn.v_proj.weight True\n",
      "model.layers.31.self_attn.o_proj.weight True\n",
      "model.layers.31.mlp.gate_proj.weight False\n",
      "model.layers.31.mlp.up_proj.weight False\n",
      "model.layers.31.mlp.down_proj.weight False\n",
      "model.layers.31.input_layernorm.weight False\n",
      "model.layers.31.post_attention_layernorm.weight False\n",
      "model.norm.weight False\n",
      "lm_head.weight True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "420cd6a6-b439-451b-980d-72bc540aba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 1470103552\n"
     ]
    }
   ],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_trainable_params = count_trainable_parameters(model)\n",
    "print(f\"Number of trainable parameters: {num_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8beff984-4201-4232-a7fc-da7c4a01c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='training_log.txt', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff98367e-119c-46af-b76b-5733a4f2d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_set = json.load(open(\"data/eval_set.json\", \"r\"))[:10] # TODO!!!!\n",
    "eval_set = json.load(open(\"data/eval_set.json\", \"r\"))\n",
    "train_set = json.load(open(\"data/train_set.json\", \"r\"))\n",
    "def custom_evaluation(model, epoch, short=True):\n",
    "    if short:\n",
    "        keywords = [e['keyword'] for e in eval_set if e['difficulty'] == \"Easy\"]\n",
    "    else:\n",
    "        keywords = [e['keyword'] for e in eval_set]\n",
    "\n",
    "    games = run_games(\n",
    "        keywords,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        id_eot,\n",
    "        batch_size=15,\n",
    "    )\n",
    "    if not short:\n",
    "        pickle.dump(games, open(f\"full_eval_{epoch}.pkl\", \"wb\"))\n",
    "    return sum([g.win for g in games]) / len(games)\n",
    "\n",
    "def custom_evaluation_on_train(model, n_examples=100):\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    random.shuffle(train_set)\n",
    "    \n",
    "    keywords = [e['keyword'] for e in train_set[:n_examples]]\n",
    "    games = run_games(\n",
    "        keywords,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        id_eot,\n",
    "        batch_size=15,\n",
    "    )\n",
    "    return sum([g.win for g in games]) / len(games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7a336-fab2-4665-883d-606b9cc8c505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c55f6ab-cfea-4963-9ca9-e183eeefa48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl.trainer import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "data_collator = DataCollatorForCompletionOnlyLM(response_template=\"<|start_header_id|>assistant<|end_header_id|>\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93e92ddb-5a73-4d8c-8c01-f70f5d59c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12e4b4-a785-4e25-9abc-4d5d3993928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a7960e1-61c6-48ac-b3a2-c8e1e993a3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:352: UserWarning: You passed a `num_of_sequences` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0328ad86056c49b08ff3898edaf3823e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16603 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d826acbb595a452185fb6556e855cd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='665' max='665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [665/665 1:00:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.838400</td>\n",
       "      <td>0.733219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.599300</td>\n",
       "      <td>0.704635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.698442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.566400</td>\n",
       "      <td>0.697272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Train Loss: 0.63388595007416\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 01:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Eval Loss: 0.6964104175567627\n",
      "Processing batch of games 2024-07-25 09:29:41.162127\n",
      "Processing batch of games 2024-07-25 09:30:44.106538\n",
      "Processing batch of games 2024-07-25 09:32:03.887699\n",
      "Epoch 0 - Custom Eval: 0.08108108108108109\n",
      "Processing batch of games 2024-07-25 09:32:41.498718\n",
      "Processing batch of games 2024-07-25 09:33:44.521859\n",
      "Processing batch of games 2024-07-25 09:35:00.919580\n",
      "Processing batch of games 2024-07-25 09:36:12.841255\n",
      "Processing batch of games 2024-07-25 09:37:22.326015\n",
      "Processing batch of games 2024-07-25 09:38:36.518110\n",
      "Processing batch of games 2024-07-25 09:39:52.614469\n",
      "Processing batch of games 2024-07-25 09:41:04.384166\n",
      "Processing batch of games 2024-07-25 09:42:23.205899\n",
      "Processing batch of games 2024-07-25 09:43:39.035542\n",
      "Epoch 0 - Custom Eval (full): 0.050359712230215826\n",
      "Processing batch of games 2024-07-25 09:44:13.208081\n",
      "Processing batch of games 2024-07-25 09:45:23.952848\n",
      "Processing batch of games 2024-07-25 09:46:34.631723\n",
      "Processing batch of games 2024-07-25 09:47:42.847138\n",
      "Processing batch of games 2024-07-25 09:48:53.491632\n",
      "Processing batch of games 2024-07-25 09:50:03.619625\n",
      "Processing batch of games 2024-07-25 09:51:07.944691\n",
      "Epoch 0 - Custom Eval (full train): 0.06\n",
      "Finished epoch 1\n"
     ]
    }
   ],
   "source": [
    "save_epochs = set([0])\n",
    "cumulative_epoch = 0\n",
    "for ds, num_epochs in (\n",
    "    # (ds_basic, 1),\n",
    "    # (ds_hints, 1),\n",
    "    (ds_snap, 1),\n",
    "):\n",
    "    for epoch in range(num_epochs):\n",
    "        training_args = SFTConfig(\n",
    "            output_dir=\"./results\",\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=25,\n",
    "            per_device_eval_batch_size=25,\n",
    "            save_strategy=\"no\",\n",
    "            learning_rate=1e-05,\n",
    "            weight_decay=0.2,\n",
    "            bf16=True,\n",
    "            lr_scheduler_type=\"linear\",\n",
    "            warmup_ratio=0.1,\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=150,\n",
    "            logging_steps=150,\n",
    "            neftune_noise_alpha=None,\n",
    "            max_seq_length=5000,\n",
    "            num_of_sequences=5000,\n",
    "            dataset_text_field=\"texts\",\n",
    "        )\n",
    "\n",
    "        trainer = SFTTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=ds,\n",
    "            eval_dataset=ds_eval,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        train_result = trainer.train()\n",
    "        train_loss = train_result.training_loss\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        \n",
    "        eval_result = trainer.evaluate()\n",
    "        eval_loss = eval_result['eval_loss']\n",
    "        \n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        \n",
    "        eval_metrics = custom_evaluation(model, cumulative_epoch)\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "        \n",
    "        if cumulative_epoch in save_epochs:\n",
    "            # TODO!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            # output_dir = f\"./results/llama_{cumulative_epoch}\"\n",
    "            # os.makedirs(output_dir, exist_ok=True)\n",
    "            # model.save_pretrained(output_dir)\n",
    "            # tokenizer.save_pretrained(output_dir)\n",
    "            eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "            logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "            print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "            eval_metrics_on_train = custom_evaluation_on_train(model)\n",
    "            logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "            print(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "        \n",
    "        print(f\"Finished epoch {cumulative_epoch + 1}\")\n",
    "        cumulative_epoch += 1  # Increment the overall epoch counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8462c670-f579-4c79-a640-28651147e059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch of games 2024-07-25 10:09:24.269525\n",
      "Processing batch of games 2024-07-25 10:10:55.196423\n",
      "Processing batch of games 2024-07-25 10:12:17.819128\n",
      "Epoch 100 - Custom Eval: 0.02702702702702703\n",
      "Processing batch of games 2024-07-25 10:12:58.992802\n",
      "Processing batch of games 2024-07-25 10:14:32.838505\n",
      "Processing batch of games 2024-07-25 10:16:13.000444\n",
      "Processing batch of games 2024-07-25 10:17:37.062857\n",
      "Processing batch of games 2024-07-25 10:18:52.478248\n",
      "Processing batch of games 2024-07-25 10:20:16.587125\n",
      "Processing batch of games 2024-07-25 10:21:53.740797\n",
      "Processing batch of games 2024-07-25 10:23:17.495005\n",
      "Processing batch of games 2024-07-25 10:24:45.651247\n",
      "Processing batch of games 2024-07-25 10:26:05.676559\n",
      "Epoch 100 - Custom Eval (full): 0.007194244604316547\n",
      "Processing batch of games 2024-07-25 10:26:36.769083\n",
      "Processing batch of games 2024-07-25 10:28:00.031064\n",
      "Processing batch of games 2024-07-25 10:29:49.797583\n",
      "Processing batch of games 2024-07-25 10:31:15.785376\n",
      "Processing batch of games 2024-07-25 10:32:37.224353\n",
      "Processing batch of games 2024-07-25 10:33:57.407578\n",
      "Processing batch of games 2024-07-25 10:35:18.837119\n",
      "Epoch 100 - Custom Eval (full train): 0.0\n"
     ]
    }
   ],
   "source": [
    "cumulative_epoch = 100\n",
    "eval_metrics = custom_evaluation(model, cumulative_epoch)\n",
    "logging.info(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "print(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "eval_metrics_on_train = custom_evaluation_on_train(model)\n",
    "logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "print(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222398fa-68ec-417d-a84c-5afa32a01fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_metrics = custom_evaluation(model, cumulative_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277c19c-c4de-4518-bdf9-fcacab554e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a254c-c781-482e-9c93-27180f5386f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af16a47-7212-49ee-98a9-3fe2ccb20267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = f\"./results/llama_{cumulative_epoch}\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# model.save_pretrained(output_dir)\n",
    "# tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2046b48-9c0f-4f63-b5a5-68f36883d9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929d6b8-e82f-4ccd-ae6e-9c1864a4e611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08791ce7-0094-4ce9-b2a1-fb8d420eac87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9d05b-dbee-4be2-a506-745cd17b00ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6062d-8ea3-4f83-b821-db91b132d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_metrics = custom_evaluation(model, 111, short=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476350e1-52ab-4081-b623-9b864dc2aa81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d95f6-b0f8-4e9a-96b9-0d0d49c9ffb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec16dce-c7c5-42e8-8e6c-e867807c5062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb7f8b67-9e0e-461f-90cf-23ac41143d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:352: UserWarning: You passed a `num_of_sequences` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c845d25682da4bd8b411d7d2721ee365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bf8a1648fa47dfa6603dc55c8fcd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='172' max='172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [172/172 17:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.730300</td>\n",
       "      <td>0.161857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Train Loss: 0.6553056808405144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 01:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Eval Loss: 0.16271020472049713\n",
      "Processing batch of games 2024-07-25 14:14:43.680049\n",
      "Processing batch of games 2024-07-25 14:15:57.433648\n",
      "Processing batch of games 2024-07-25 14:17:28.763690\n",
      "Epoch 0 - Custom Eval: 0.08108108108108109\n",
      "Processing batch of games 2024-07-25 14:18:15.573899\n",
      "Processing batch of games 2024-07-25 14:19:51.400755\n",
      "Processing batch of games 2024-07-25 14:21:17.810188\n",
      "Processing batch of games 2024-07-25 14:22:39.612578\n",
      "Processing batch of games 2024-07-25 14:23:45.895106\n",
      "Processing batch of games 2024-07-25 14:25:01.293184\n",
      "Processing batch of games 2024-07-25 14:26:19.515741\n",
      "Processing batch of games 2024-07-25 14:27:54.013202\n",
      "Processing batch of games 2024-07-25 14:29:35.996222\n",
      "Processing batch of games 2024-07-25 14:31:00.559145\n",
      "Epoch 0 - Custom Eval (full): 0.050359712230215826\n",
      "Processing batch of games 2024-07-25 14:31:33.966403\n",
      "Processing batch of games 2024-07-25 14:32:59.482198\n",
      "Processing batch of games 2024-07-25 14:34:32.018090\n",
      "Processing batch of games 2024-07-25 14:35:57.720523\n",
      "Processing batch of games 2024-07-25 14:37:15.380694\n",
      "Processing batch of games 2024-07-25 14:38:37.519102\n",
      "Processing batch of games 2024-07-25 14:39:55.653515\n",
      "Epoch 0 - Custom Eval (full train): 0.06\n",
      "Finished epoch 1\n"
     ]
    }
   ],
   "source": [
    "save_epochs = set([0])\n",
    "cumulative_epoch = 0\n",
    "for ds, num_epochs in (\n",
    "    # (ds_basic, 1),\n",
    "    (ds_hints, 1),\n",
    "    # (ds_snap, 1),\n",
    "):\n",
    "    for epoch in range(num_epochs):\n",
    "        training_args = SFTConfig(\n",
    "            output_dir=\"./results\",\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=25,\n",
    "            per_device_eval_batch_size=25,\n",
    "            save_strategy=\"no\",\n",
    "            learning_rate=1e-05,\n",
    "            weight_decay=0.25,\n",
    "            bf16=True,\n",
    "            lr_scheduler_type=\"linear\",\n",
    "            warmup_ratio=0.1,\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=150,\n",
    "            logging_steps=150,\n",
    "            neftune_noise_alpha=None,\n",
    "            max_seq_length=5000,\n",
    "            num_of_sequences=5000,\n",
    "            dataset_text_field=\"texts\",\n",
    "        )\n",
    "\n",
    "        trainer = SFTTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=ds,\n",
    "            eval_dataset=ds_eval,\n",
    "            tokenizer=tokenizer,\n",
    "            # data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        train_result = trainer.train()\n",
    "        train_loss = train_result.training_loss\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        \n",
    "        eval_result = trainer.evaluate()\n",
    "        eval_loss = eval_result['eval_loss']\n",
    "        \n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        \n",
    "        eval_metrics = custom_evaluation(model, cumulative_epoch)\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "        \n",
    "        if cumulative_epoch in save_epochs:\n",
    "            # TODO !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            # output_dir = f\"./results/llama_no_mask_{cumulative_epoch}\"\n",
    "            # os.makedirs(output_dir, exist_ok=True)\n",
    "            # model.save_pretrained(output_dir)\n",
    "            # tokenizer.save_pretrained(output_dir)\n",
    "            eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "            logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "            print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "            eval_metrics_on_train = custom_evaluation_on_train(model)\n",
    "            logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "            print(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "       \n",
    "        print(f\"Finished epoch {cumulative_epoch + 1}\")\n",
    "        cumulative_epoch += 1  # Increment the overall epoch counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb203df2-6bc9-492f-920d-7236b4a90424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_metrics = custom_evaluation(model, cumulative_epoch)\n",
    "# logging.info(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "# print(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "# eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "# logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "# print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "# eval_metrics_on_train = custom_evaluation_on_train(model)\n",
    "# logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "# print(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919bdc64-9dd4-4a63-ac68-844bd193bf32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8255dbec-a4dd-4cea-abb7-9550a54de60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0066d42-a20a-450f-88a4-c2c3ddf0476b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8142da-1989-4190-ac8c-87164bd429f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7275f18-44bb-4dc7-9de6-7a9dea8ad953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc6161-56ae-490c-86b6-0ff7e4b62adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./results/llama_no_mask_2/config.json\n",
      "Configuration saved in ./results/llama_no_mask_2/generation_config.json\n",
      "The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 4 checkpoint shards. You can find where each parameters has been saved in the index located at ./results/llama_no_mask_2/model.safetensors.index.json.\n",
      "tokenizer config file saved in ./results/llama_no_mask_2/tokenizer_config.json\n",
      "Special tokens file saved in ./results/llama_no_mask_2/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch of games 2024-07-24 20:30:57.513520\n"
     ]
    }
   ],
   "source": [
    "output_dir = f\"./results/llama_no_mask_{cumulative_epoch}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74303228-a769-459d-a158-6c53b289bd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba99374-31cf-49d1-9383-6840eed515d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78424d2b-ae79-4d24-b16c-1170cbc9716d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b579ace-e152-4b94-a042-52893d5e4984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
