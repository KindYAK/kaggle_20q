{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b772a87-43f9-49c2-87cf-bcf578b7e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, get_scheduler\n",
    "import torch\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import os\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "HfFolder.save_token(os.environ['HUGGINGFACE_TOKEN'])\n",
    "\n",
    "import datasets\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0069e6-a5fe-4967-8ccb-7e1402960eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5901d4066e494896b9506b9b232aa5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3aea87-d472-4091-8223-af6b90675bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd6699-d243-403a-86cc-25650250edb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05bd279f-56d3-48af-a35a-a83fefeda231",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_basic = pickle.load(open(\"data_collection/!final_dataset_11194_basic.pkl\", \"rb\"))\n",
    "d_hints = pickle.load(open(\"data_collection/!final_dataset_6016_with_hints_after_n_step.pkl\", \"rb\"))\n",
    "d_snap = pickle.load(open(\"data_collection/!final_dataset_17476_from_snapshots_fixed.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99f0d0f-7596-46c1-b550-fa991cb14f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, split_ratio=0.01):\n",
    "    random.shuffle(dataset)\n",
    "    split_index = int(len(dataset) * split_ratio)\n",
    "    eval_set = dataset[:split_index]\n",
    "    train_set = dataset[split_index:]\n",
    "    return train_set, eval_set\n",
    "\n",
    "d_basic, d_basic_eval = split_dataset(d_basic)\n",
    "d_hints, d_hints_eval = split_dataset(d_hints)\n",
    "d_snap, d_snap_eval = split_dataset(d_snap)\n",
    "\n",
    "d_eval = d_basic_eval + d_hints_eval + d_snap_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ecaa5c-2253-4ff0-a397-29ebca4878da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO TEMP!\n",
    "# d_basic = d_basic[:30]\n",
    "# d_hints = d_hints[:30]\n",
    "# d_snap = d_snap[:30]\n",
    "# d_eval = d_eval[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1bd15-cb7b-4315-99a1-9d042c96dcd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e35085d-eebe-4ca2-94de-62f37a2cb231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    prompts = [item['prompt'] for item in data]\n",
    "    responses = [item['response'] for item in data]\n",
    "    return datasets.Dataset.from_dict({\"prompt\": prompts, \"response\": responses})\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['prompt'], text_target=examples['response'], truncation=True, padding=\"max_length\", max_length=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b0b00c2-6122-422c-8e1b-30bfa3af73a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9a9e6b67b544668d0080596e67ba5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1926f93cc97b458e966a73b6f25340d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7156718448f64cef9a176822cb4993c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35fc3e21ebf4f56911b5540bcb23d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/302 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = prepare_data(d_basic)\n",
    "ds_basic = dataset.map(tokenize_function, batched=True).shuffle(seed=42)\n",
    "\n",
    "dataset = prepare_data(d_hints)\n",
    "ds_hints = dataset.map(tokenize_function, batched=True).shuffle(seed=42)\n",
    "\n",
    "dataset = prepare_data(d_snap)\n",
    "ds_snap = dataset.map(tokenize_function, batched=True).shuffle(seed=42)\n",
    "\n",
    "dataset = prepare_data(d_eval)\n",
    "ds_eval = dataset.map(tokenize_function, batched=True).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84888f00-96b3-4d4c-ad91-ed8e7c21b937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7180629-d2b0-4865-86ed-16851698266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if \"model.layers.\" not in name and not \"head\" in name and not \"embed_tokens\" in name:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "#     if \"mlp\" in name:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "#     if \"norm\" in name:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "#     if \"head\" in name or \"embed_tokens\" in name:\n",
    "#         continue\n",
    "#     layer_num = int(name.split(\".\")[2])\n",
    "#     if layer_num <= 15:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"model.layers.\" not in name and not \"head\" in name:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "    if \"mlp\" in name:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "    if \"norm\" in name:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "    if \"head\" in name:\n",
    "        continue\n",
    "    layer_num = int(name.split(\".\")[2])\n",
    "    if layer_num <= 15:\n",
    "        param.requires_grad = False\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d48c4e6-2f3f-4b52-aa31-51bf1be45144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight False\n",
      "model.layers.0.self_attn.q_proj.weight False\n",
      "model.layers.0.self_attn.k_proj.weight False\n",
      "model.layers.0.self_attn.v_proj.weight False\n",
      "model.layers.0.self_attn.o_proj.weight False\n",
      "model.layers.0.mlp.gate_proj.weight False\n",
      "model.layers.0.mlp.up_proj.weight False\n",
      "model.layers.0.mlp.down_proj.weight False\n",
      "model.layers.0.input_layernorm.weight False\n",
      "model.layers.0.post_attention_layernorm.weight False\n",
      "model.layers.1.self_attn.q_proj.weight False\n",
      "model.layers.1.self_attn.k_proj.weight False\n",
      "model.layers.1.self_attn.v_proj.weight False\n",
      "model.layers.1.self_attn.o_proj.weight False\n",
      "model.layers.1.mlp.gate_proj.weight False\n",
      "model.layers.1.mlp.up_proj.weight False\n",
      "model.layers.1.mlp.down_proj.weight False\n",
      "model.layers.1.input_layernorm.weight False\n",
      "model.layers.1.post_attention_layernorm.weight False\n",
      "model.layers.2.self_attn.q_proj.weight False\n",
      "model.layers.2.self_attn.k_proj.weight False\n",
      "model.layers.2.self_attn.v_proj.weight False\n",
      "model.layers.2.self_attn.o_proj.weight False\n",
      "model.layers.2.mlp.gate_proj.weight False\n",
      "model.layers.2.mlp.up_proj.weight False\n",
      "model.layers.2.mlp.down_proj.weight False\n",
      "model.layers.2.input_layernorm.weight False\n",
      "model.layers.2.post_attention_layernorm.weight False\n",
      "model.layers.3.self_attn.q_proj.weight False\n",
      "model.layers.3.self_attn.k_proj.weight False\n",
      "model.layers.3.self_attn.v_proj.weight False\n",
      "model.layers.3.self_attn.o_proj.weight False\n",
      "model.layers.3.mlp.gate_proj.weight False\n",
      "model.layers.3.mlp.up_proj.weight False\n",
      "model.layers.3.mlp.down_proj.weight False\n",
      "model.layers.3.input_layernorm.weight False\n",
      "model.layers.3.post_attention_layernorm.weight False\n",
      "model.layers.4.self_attn.q_proj.weight False\n",
      "model.layers.4.self_attn.k_proj.weight False\n",
      "model.layers.4.self_attn.v_proj.weight False\n",
      "model.layers.4.self_attn.o_proj.weight False\n",
      "model.layers.4.mlp.gate_proj.weight False\n",
      "model.layers.4.mlp.up_proj.weight False\n",
      "model.layers.4.mlp.down_proj.weight False\n",
      "model.layers.4.input_layernorm.weight False\n",
      "model.layers.4.post_attention_layernorm.weight False\n",
      "model.layers.5.self_attn.q_proj.weight False\n",
      "model.layers.5.self_attn.k_proj.weight False\n",
      "model.layers.5.self_attn.v_proj.weight False\n",
      "model.layers.5.self_attn.o_proj.weight False\n",
      "model.layers.5.mlp.gate_proj.weight False\n",
      "model.layers.5.mlp.up_proj.weight False\n",
      "model.layers.5.mlp.down_proj.weight False\n",
      "model.layers.5.input_layernorm.weight False\n",
      "model.layers.5.post_attention_layernorm.weight False\n",
      "model.layers.6.self_attn.q_proj.weight False\n",
      "model.layers.6.self_attn.k_proj.weight False\n",
      "model.layers.6.self_attn.v_proj.weight False\n",
      "model.layers.6.self_attn.o_proj.weight False\n",
      "model.layers.6.mlp.gate_proj.weight False\n",
      "model.layers.6.mlp.up_proj.weight False\n",
      "model.layers.6.mlp.down_proj.weight False\n",
      "model.layers.6.input_layernorm.weight False\n",
      "model.layers.6.post_attention_layernorm.weight False\n",
      "model.layers.7.self_attn.q_proj.weight False\n",
      "model.layers.7.self_attn.k_proj.weight False\n",
      "model.layers.7.self_attn.v_proj.weight False\n",
      "model.layers.7.self_attn.o_proj.weight False\n",
      "model.layers.7.mlp.gate_proj.weight False\n",
      "model.layers.7.mlp.up_proj.weight False\n",
      "model.layers.7.mlp.down_proj.weight False\n",
      "model.layers.7.input_layernorm.weight False\n",
      "model.layers.7.post_attention_layernorm.weight False\n",
      "model.layers.8.self_attn.q_proj.weight False\n",
      "model.layers.8.self_attn.k_proj.weight False\n",
      "model.layers.8.self_attn.v_proj.weight False\n",
      "model.layers.8.self_attn.o_proj.weight False\n",
      "model.layers.8.mlp.gate_proj.weight False\n",
      "model.layers.8.mlp.up_proj.weight False\n",
      "model.layers.8.mlp.down_proj.weight False\n",
      "model.layers.8.input_layernorm.weight False\n",
      "model.layers.8.post_attention_layernorm.weight False\n",
      "model.layers.9.self_attn.q_proj.weight False\n",
      "model.layers.9.self_attn.k_proj.weight False\n",
      "model.layers.9.self_attn.v_proj.weight False\n",
      "model.layers.9.self_attn.o_proj.weight False\n",
      "model.layers.9.mlp.gate_proj.weight False\n",
      "model.layers.9.mlp.up_proj.weight False\n",
      "model.layers.9.mlp.down_proj.weight False\n",
      "model.layers.9.input_layernorm.weight False\n",
      "model.layers.9.post_attention_layernorm.weight False\n",
      "model.layers.10.self_attn.q_proj.weight False\n",
      "model.layers.10.self_attn.k_proj.weight False\n",
      "model.layers.10.self_attn.v_proj.weight False\n",
      "model.layers.10.self_attn.o_proj.weight False\n",
      "model.layers.10.mlp.gate_proj.weight False\n",
      "model.layers.10.mlp.up_proj.weight False\n",
      "model.layers.10.mlp.down_proj.weight False\n",
      "model.layers.10.input_layernorm.weight False\n",
      "model.layers.10.post_attention_layernorm.weight False\n",
      "model.layers.11.self_attn.q_proj.weight False\n",
      "model.layers.11.self_attn.k_proj.weight False\n",
      "model.layers.11.self_attn.v_proj.weight False\n",
      "model.layers.11.self_attn.o_proj.weight False\n",
      "model.layers.11.mlp.gate_proj.weight False\n",
      "model.layers.11.mlp.up_proj.weight False\n",
      "model.layers.11.mlp.down_proj.weight False\n",
      "model.layers.11.input_layernorm.weight False\n",
      "model.layers.11.post_attention_layernorm.weight False\n",
      "model.layers.12.self_attn.q_proj.weight False\n",
      "model.layers.12.self_attn.k_proj.weight False\n",
      "model.layers.12.self_attn.v_proj.weight False\n",
      "model.layers.12.self_attn.o_proj.weight False\n",
      "model.layers.12.mlp.gate_proj.weight False\n",
      "model.layers.12.mlp.up_proj.weight False\n",
      "model.layers.12.mlp.down_proj.weight False\n",
      "model.layers.12.input_layernorm.weight False\n",
      "model.layers.12.post_attention_layernorm.weight False\n",
      "model.layers.13.self_attn.q_proj.weight False\n",
      "model.layers.13.self_attn.k_proj.weight False\n",
      "model.layers.13.self_attn.v_proj.weight False\n",
      "model.layers.13.self_attn.o_proj.weight False\n",
      "model.layers.13.mlp.gate_proj.weight False\n",
      "model.layers.13.mlp.up_proj.weight False\n",
      "model.layers.13.mlp.down_proj.weight False\n",
      "model.layers.13.input_layernorm.weight False\n",
      "model.layers.13.post_attention_layernorm.weight False\n",
      "model.layers.14.self_attn.q_proj.weight False\n",
      "model.layers.14.self_attn.k_proj.weight False\n",
      "model.layers.14.self_attn.v_proj.weight False\n",
      "model.layers.14.self_attn.o_proj.weight False\n",
      "model.layers.14.mlp.gate_proj.weight False\n",
      "model.layers.14.mlp.up_proj.weight False\n",
      "model.layers.14.mlp.down_proj.weight False\n",
      "model.layers.14.input_layernorm.weight False\n",
      "model.layers.14.post_attention_layernorm.weight False\n",
      "model.layers.15.self_attn.q_proj.weight False\n",
      "model.layers.15.self_attn.k_proj.weight False\n",
      "model.layers.15.self_attn.v_proj.weight False\n",
      "model.layers.15.self_attn.o_proj.weight False\n",
      "model.layers.15.mlp.gate_proj.weight False\n",
      "model.layers.15.mlp.up_proj.weight False\n",
      "model.layers.15.mlp.down_proj.weight False\n",
      "model.layers.15.input_layernorm.weight False\n",
      "model.layers.15.post_attention_layernorm.weight False\n",
      "model.layers.16.self_attn.q_proj.weight True\n",
      "model.layers.16.self_attn.k_proj.weight True\n",
      "model.layers.16.self_attn.v_proj.weight True\n",
      "model.layers.16.self_attn.o_proj.weight True\n",
      "model.layers.16.mlp.gate_proj.weight False\n",
      "model.layers.16.mlp.up_proj.weight False\n",
      "model.layers.16.mlp.down_proj.weight False\n",
      "model.layers.16.input_layernorm.weight False\n",
      "model.layers.16.post_attention_layernorm.weight False\n",
      "model.layers.17.self_attn.q_proj.weight True\n",
      "model.layers.17.self_attn.k_proj.weight True\n",
      "model.layers.17.self_attn.v_proj.weight True\n",
      "model.layers.17.self_attn.o_proj.weight True\n",
      "model.layers.17.mlp.gate_proj.weight False\n",
      "model.layers.17.mlp.up_proj.weight False\n",
      "model.layers.17.mlp.down_proj.weight False\n",
      "model.layers.17.input_layernorm.weight False\n",
      "model.layers.17.post_attention_layernorm.weight False\n",
      "model.layers.18.self_attn.q_proj.weight True\n",
      "model.layers.18.self_attn.k_proj.weight True\n",
      "model.layers.18.self_attn.v_proj.weight True\n",
      "model.layers.18.self_attn.o_proj.weight True\n",
      "model.layers.18.mlp.gate_proj.weight False\n",
      "model.layers.18.mlp.up_proj.weight False\n",
      "model.layers.18.mlp.down_proj.weight False\n",
      "model.layers.18.input_layernorm.weight False\n",
      "model.layers.18.post_attention_layernorm.weight False\n",
      "model.layers.19.self_attn.q_proj.weight True\n",
      "model.layers.19.self_attn.k_proj.weight True\n",
      "model.layers.19.self_attn.v_proj.weight True\n",
      "model.layers.19.self_attn.o_proj.weight True\n",
      "model.layers.19.mlp.gate_proj.weight False\n",
      "model.layers.19.mlp.up_proj.weight False\n",
      "model.layers.19.mlp.down_proj.weight False\n",
      "model.layers.19.input_layernorm.weight False\n",
      "model.layers.19.post_attention_layernorm.weight False\n",
      "model.layers.20.self_attn.q_proj.weight True\n",
      "model.layers.20.self_attn.k_proj.weight True\n",
      "model.layers.20.self_attn.v_proj.weight True\n",
      "model.layers.20.self_attn.o_proj.weight True\n",
      "model.layers.20.mlp.gate_proj.weight False\n",
      "model.layers.20.mlp.up_proj.weight False\n",
      "model.layers.20.mlp.down_proj.weight False\n",
      "model.layers.20.input_layernorm.weight False\n",
      "model.layers.20.post_attention_layernorm.weight False\n",
      "model.layers.21.self_attn.q_proj.weight True\n",
      "model.layers.21.self_attn.k_proj.weight True\n",
      "model.layers.21.self_attn.v_proj.weight True\n",
      "model.layers.21.self_attn.o_proj.weight True\n",
      "model.layers.21.mlp.gate_proj.weight False\n",
      "model.layers.21.mlp.up_proj.weight False\n",
      "model.layers.21.mlp.down_proj.weight False\n",
      "model.layers.21.input_layernorm.weight False\n",
      "model.layers.21.post_attention_layernorm.weight False\n",
      "model.layers.22.self_attn.q_proj.weight True\n",
      "model.layers.22.self_attn.k_proj.weight True\n",
      "model.layers.22.self_attn.v_proj.weight True\n",
      "model.layers.22.self_attn.o_proj.weight True\n",
      "model.layers.22.mlp.gate_proj.weight False\n",
      "model.layers.22.mlp.up_proj.weight False\n",
      "model.layers.22.mlp.down_proj.weight False\n",
      "model.layers.22.input_layernorm.weight False\n",
      "model.layers.22.post_attention_layernorm.weight False\n",
      "model.layers.23.self_attn.q_proj.weight True\n",
      "model.layers.23.self_attn.k_proj.weight True\n",
      "model.layers.23.self_attn.v_proj.weight True\n",
      "model.layers.23.self_attn.o_proj.weight True\n",
      "model.layers.23.mlp.gate_proj.weight False\n",
      "model.layers.23.mlp.up_proj.weight False\n",
      "model.layers.23.mlp.down_proj.weight False\n",
      "model.layers.23.input_layernorm.weight False\n",
      "model.layers.23.post_attention_layernorm.weight False\n",
      "model.layers.24.self_attn.q_proj.weight True\n",
      "model.layers.24.self_attn.k_proj.weight True\n",
      "model.layers.24.self_attn.v_proj.weight True\n",
      "model.layers.24.self_attn.o_proj.weight True\n",
      "model.layers.24.mlp.gate_proj.weight False\n",
      "model.layers.24.mlp.up_proj.weight False\n",
      "model.layers.24.mlp.down_proj.weight False\n",
      "model.layers.24.input_layernorm.weight False\n",
      "model.layers.24.post_attention_layernorm.weight False\n",
      "model.layers.25.self_attn.q_proj.weight True\n",
      "model.layers.25.self_attn.k_proj.weight True\n",
      "model.layers.25.self_attn.v_proj.weight True\n",
      "model.layers.25.self_attn.o_proj.weight True\n",
      "model.layers.25.mlp.gate_proj.weight False\n",
      "model.layers.25.mlp.up_proj.weight False\n",
      "model.layers.25.mlp.down_proj.weight False\n",
      "model.layers.25.input_layernorm.weight False\n",
      "model.layers.25.post_attention_layernorm.weight False\n",
      "model.layers.26.self_attn.q_proj.weight True\n",
      "model.layers.26.self_attn.k_proj.weight True\n",
      "model.layers.26.self_attn.v_proj.weight True\n",
      "model.layers.26.self_attn.o_proj.weight True\n",
      "model.layers.26.mlp.gate_proj.weight False\n",
      "model.layers.26.mlp.up_proj.weight False\n",
      "model.layers.26.mlp.down_proj.weight False\n",
      "model.layers.26.input_layernorm.weight False\n",
      "model.layers.26.post_attention_layernorm.weight False\n",
      "model.layers.27.self_attn.q_proj.weight True\n",
      "model.layers.27.self_attn.k_proj.weight True\n",
      "model.layers.27.self_attn.v_proj.weight True\n",
      "model.layers.27.self_attn.o_proj.weight True\n",
      "model.layers.27.mlp.gate_proj.weight False\n",
      "model.layers.27.mlp.up_proj.weight False\n",
      "model.layers.27.mlp.down_proj.weight False\n",
      "model.layers.27.input_layernorm.weight False\n",
      "model.layers.27.post_attention_layernorm.weight False\n",
      "model.layers.28.self_attn.q_proj.weight True\n",
      "model.layers.28.self_attn.k_proj.weight True\n",
      "model.layers.28.self_attn.v_proj.weight True\n",
      "model.layers.28.self_attn.o_proj.weight True\n",
      "model.layers.28.mlp.gate_proj.weight False\n",
      "model.layers.28.mlp.up_proj.weight False\n",
      "model.layers.28.mlp.down_proj.weight False\n",
      "model.layers.28.input_layernorm.weight False\n",
      "model.layers.28.post_attention_layernorm.weight False\n",
      "model.layers.29.self_attn.q_proj.weight True\n",
      "model.layers.29.self_attn.k_proj.weight True\n",
      "model.layers.29.self_attn.v_proj.weight True\n",
      "model.layers.29.self_attn.o_proj.weight True\n",
      "model.layers.29.mlp.gate_proj.weight False\n",
      "model.layers.29.mlp.up_proj.weight False\n",
      "model.layers.29.mlp.down_proj.weight False\n",
      "model.layers.29.input_layernorm.weight False\n",
      "model.layers.29.post_attention_layernorm.weight False\n",
      "model.layers.30.self_attn.q_proj.weight True\n",
      "model.layers.30.self_attn.k_proj.weight True\n",
      "model.layers.30.self_attn.v_proj.weight True\n",
      "model.layers.30.self_attn.o_proj.weight True\n",
      "model.layers.30.mlp.gate_proj.weight False\n",
      "model.layers.30.mlp.up_proj.weight False\n",
      "model.layers.30.mlp.down_proj.weight False\n",
      "model.layers.30.input_layernorm.weight False\n",
      "model.layers.30.post_attention_layernorm.weight False\n",
      "model.layers.31.self_attn.q_proj.weight True\n",
      "model.layers.31.self_attn.k_proj.weight True\n",
      "model.layers.31.self_attn.v_proj.weight True\n",
      "model.layers.31.self_attn.o_proj.weight True\n",
      "model.layers.31.mlp.gate_proj.weight False\n",
      "model.layers.31.mlp.up_proj.weight False\n",
      "model.layers.31.mlp.down_proj.weight False\n",
      "model.layers.31.input_layernorm.weight False\n",
      "model.layers.31.post_attention_layernorm.weight False\n",
      "model.norm.weight False\n",
      "lm_head.weight True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "420cd6a6-b439-451b-980d-72bc540aba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 1196425216\n"
     ]
    }
   ],
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_trainable_params = count_trainable_parameters(model)\n",
    "print(f\"Number of trainable parameters: {num_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8beff984-4201-4232-a7fc-da7c4a01c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='training_log.txt', level=logging.INFO)\n",
    "\n",
    "save_epochs = set([0, 4, 9, 14, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff98367e-119c-46af-b76b-5733a4f2d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_evaluation(model):\n",
    "    # Placeholder for custom evaluation logic\n",
    "    return {\"custom_metric\": 0.0}  # TODO Replace with actual evaluation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93e92ddb-5a73-4d8c-8c01-f70f5d59c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a7960e1-61c6-48ac-b3a2-c8e1e993a3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 65/830 10:48 < 2:11:20, 0.10 it/s, Epoch 0.08/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>11.595554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>11.212341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>11.050000</td>\n",
       "      <td>10.344791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>8.804544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.930135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>4.596248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7240059c5f30>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cumulative_epoch = 0\n",
    "for ds, num_epochs in (\n",
    "    (ds_basic, 10),\n",
    "    (ds_hints, 10),\n",
    "    (ds_snap, 5),\n",
    "):\n",
    "    for epoch in range(num_epochs):\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./results\",\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=10,\n",
    "            per_device_eval_batch_size=10,\n",
    "            save_strategy=\"no\",\n",
    "            learning_rate=5e-05,\n",
    "            weight_decay=0.1,\n",
    "            bf16=True,\n",
    "            lr_scheduler_type=\"cosine_with_restarts\",\n",
    "            warmup_ratio=0.1,\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=10,\n",
    "            logging_steps=10,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=ds,\n",
    "            eval_dataset=ds_eval,\n",
    "        )\n",
    "\n",
    "        train_result = trainer.train()\n",
    "        train_loss = train_result.training_loss\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        \n",
    "        eval_result = trainer.evaluate()\n",
    "        eval_loss = eval_result['eval_loss']\n",
    "        \n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        \n",
    "        eval_metrics = custom_evaluation(model)\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics['custom_metric']}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics['custom_metric']}\")\n",
    "        \n",
    "        if cumulative_epoch in save_epochs:\n",
    "            output_dir = f\"./results/llama_{cumulative_epoch}\"\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            model.save_pretrained(output_dir)\n",
    "            tokenizer.save_pretrained(output_dir)\n",
    "        \n",
    "        print(f\"Finished epoch {cumulative_epoch + 1}\")\n",
    "        cumulative_epoch += 1  # Increment the overall epoch counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277c19c-c4de-4518-bdf9-fcacab554e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af16a47-7212-49ee-98a9-3fe2ccb20267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2046b48-9c0f-4f63-b5a5-68f36883d9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929d6b8-e82f-4ccd-ae6e-9c1864a4e611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08791ce7-0094-4ce9-b2a1-fb8d420eac87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9d05b-dbee-4be2-a506-745cd17b00ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e6062d-8ea3-4f83-b821-db91b132d4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476350e1-52ab-4081-b623-9b864dc2aa81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d95f6-b0f8-4e9a-96b9-0d0d49c9ffb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec16dce-c7c5-42e8-8e6c-e867807c5062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
