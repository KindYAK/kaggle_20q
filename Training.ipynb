{
 "cells": [
  {
   "cell_type": "code",
   "id": "7b772a87-43f9-49c2-87cf-bcf578b7e129",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, get_scheduler\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from utils_simulate import run_games\n",
    "\n",
    "import os\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "HfFolder.save_token(os.environ['HUGGINGFACE_TOKEN'])\n",
    "\n",
    "import datasets\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from transformers.utils import logging\n",
    "# logging.set_verbosity_info()\n",
    "\n",
    "import logging\n",
    "from transformers.utils import logging as transformers_logging\n",
    "\n",
    "class CustomFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return 'right-padding was detected' not in record.getMessage()\n",
    "\n",
    "logger = logging.getLogger('transformers')\n",
    "\n",
    "for handler in logger.handlers:\n",
    "    handler.addFilter(CustomFilter())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d0069e6-a5fe-4967-8ccb-7e1402960eeb",
   "metadata": {},
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# model_id = \"astronomer/Llama-3-8B-Special-Tokens-Adjusted\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side='left')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side='right')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "id_eot = tokenizer.convert_tokens_to_ids([\"<|eot_id|>\"])[0]\n",
    "pad_token_id = tokenizer.convert_tokens_to_ids([\"<|end_of_text|>\"])[0]\n",
    "\n",
    "tokenizer.pad_token_id = pad_token_id\n",
    "model.config.pad_token_id = pad_token_id\n",
    "\n",
    "# tokenizer.pad_token_id = id_eot\n",
    "# model.config.pad_token_id = id_eot\n",
    "\n",
    "# tokenizer.add_special_tokens({\"pad_token\": \"<|padding_token|>\"})\n",
    "# model.config.pad_token_id = tokenizer.pad_token_id"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c3aea87-d472-4091-8223-af6b90675bd6",
   "metadata": {},
   "source": [
    "1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c870d3c9-dcfd-4852-9427-cc981d550728",
   "metadata": {},
   "source": [
    "tokenizer.pad_token, tokenizer.pad_token_id"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35cd6699-d243-403a-86cc-25650250edb6",
   "metadata": {},
   "source": [
    "id_eot, pad_token_id"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "05bd279f-56d3-48af-a35a-a83fefeda231",
   "metadata": {},
   "source": [
    "d_basic = pickle.load(open(\"data_collection/!final_dataset_11194_basic.pkl\", \"rb\"))\n",
    "d_hints = pickle.load(open(\"data_collection/!final_dataset_6016_with_hints_after_n_step.pkl\", \"rb\"))\n",
    "d_snap = pickle.load(open(\"data_collection/!final_dataset_17476_from_snapshots_fixed.pkl\", \"rb\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d99f0d0f-7596-46c1-b550-fa991cb14f02",
   "metadata": {},
   "source": [
    "def split_dataset(dataset, split_ratio=0.05):\n",
    "    random.shuffle(dataset)\n",
    "    split_index = int(len(dataset) * split_ratio)\n",
    "    eval_set = dataset[:split_index]\n",
    "    train_set = dataset[split_index:]\n",
    "    return train_set, eval_set\n",
    "\n",
    "d_basic, d_basic_eval = split_dataset(d_basic)\n",
    "d_hints, d_hints_eval = split_dataset(d_hints)\n",
    "d_snap, d_snap_eval = split_dataset(d_snap)\n",
    "\n",
    "d_eval = d_basic_eval + d_hints_eval + d_snap_eval"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d6ecaa5c-2253-4ff0-a397-29ebca4878da",
   "metadata": {},
   "source": [
    "# # # TODO TEMP!\n",
    "# d_basic = d_basic[:1000]\n",
    "# d_hints = d_hints[:30]\n",
    "# d_snap = d_snap[:30]\n",
    "# d_eval = d_eval[:30]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "04b1bd15-cb7b-4315-99a1-9d042c96dcd5",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "750dbeed-b2eb-4b56-a234-f3d2f7c3ad26",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e35085d-eebe-4ca2-94de-62f37a2cb231",
   "metadata": {},
   "source": [
    "# def prepare_data(data):\n",
    "#     prompts = [item['prompt'] for item in data]\n",
    "#     responses = [item['response'] for item in data]\n",
    "#     return datasets.Dataset.from_dict({\"prompt\": prompts, \"response\": responses})\n",
    "\n",
    "\n",
    "from utils import SYSTEM_PROMPT_ASKER, SYSTEM_PROMPT_ANSWERER\n",
    "# def prepare_inputs(chats: list[dict]):\n",
    "#     tokenizer.padding_side = \"left\"\n",
    "#     r_inputs = tokenizer.apply_chat_template(\n",
    "#         [\n",
    "#             [\n",
    "#                 {\"role\": \"system\", \"content\": SYSTEM_PROMPT_ASKER if \"only YES or NO\" not in o['prompt'] else SYSTEM_PROMPT_ANSWERER},\n",
    "#                 {\"role\": \"user\", \"content\": o['prompt']},\n",
    "#             ] for o in chats\n",
    "#         ],\n",
    "#         tokenize=True,\n",
    "#         padding=\"longest\",\n",
    "#         return_dict=True,\n",
    "#     )\n",
    "#     tokenizer.padding_side = \"right\"\n",
    "#     r_labels = tokenizer.apply_chat_template(\n",
    "#         [\n",
    "#             [\n",
    "#                 {\"role\": \"assistant\", \"content\": o['response']}\n",
    "#             ] for o in chats\n",
    "#         ],\n",
    "#         tokenize=True,\n",
    "#         padding=\"longest\",\n",
    "#         # return_dict=True,\n",
    "#     )\n",
    "#     return datasets.Dataset.from_dict(\n",
    "#         {\n",
    "#             \"input_ids\": r_inputs['input_ids'],\n",
    "#             \"attention_mask\": r_inputs['attention_mask'],\n",
    "#             \"labels\": r_labels,\n",
    "#         }\n",
    "#     ).shuffle(seed=42)\n",
    "\n",
    "\n",
    "def prepare_inputs(chats: list[dict]):\n",
    "    r_inputs = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT_ASKER if \"only YES or NO\" not in o['prompt'] else SYSTEM_PROMPT_ANSWERER},\n",
    "                {\"role\": \"user\", \"content\": o['prompt']},                \n",
    "                {\"role\": \"assistant\", \"content\": o['response']}\n",
    "            ] for o in chats\n",
    "        ],\n",
    "        tokenize=False,\n",
    "        padding=False,\n",
    "        return_dict=False,\n",
    "    )\n",
    "    return datasets.Dataset.from_dict(\n",
    "        {\"texts\": [r[:-len(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\")] for r in r_inputs]}\n",
    "    ).shuffle(seed=42)\n",
    "\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "    # return tokenizer(examples['prompt'], text_target=examples['response'], truncation=True, padding=\"max_length\", max_length=2500)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "219b2066-2cbd-4263-ae99-69870acab1b4",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7385f7f-6d9f-48ba-8376-19384319b3f8",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eab18875-5f31-4028-ac9e-181f02c0078d",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "343d12cb-f138-45c1-a43a-dee14e1592c6",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b0b00c2-6122-422c-8e1b-30bfa3af73a2",
   "metadata": {},
   "source": [
    "ds_basic = prepare_inputs(d_basic)\n",
    "print(\"ds_basic\", len(ds_basic))\n",
    "\n",
    "ds_hints = prepare_inputs(d_hints)\n",
    "print(\"d_hints\", len(d_hints))\n",
    "\n",
    "ds_snap = prepare_inputs(d_snap)\n",
    "print(\"ds_snap\", len(ds_snap))\n",
    "\n",
    "ds_eval = prepare_inputs(d_eval)\n",
    "print(\"ds_eval\", len(ds_eval))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "84888f00-96b3-4d4c-ad91-ed8e7c21b937",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7180629-d2b0-4865-86ed-16851698266c",
   "metadata": {},
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"model.layers.\" not in name and not \"head\" in name and not \"embed_tokens\" in name:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "    if \"mlp\" in name:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "    if \"norm\" in name:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "    if \"head\" in name or \"embed_tokens\" in name:\n",
    "        continue\n",
    "    layer_num = int(name.split(\".\")[2])\n",
    "    if layer_num <= 21:\n",
    "        param.requires_grad = False\n",
    "        continue\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"model.layers.\" not in name and not \"head\" in name:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "#     if \"mlp\" in name:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "#     if \"norm\" in name:\n",
    "#         param.requires_grad = False\n",
    "#         continue\n",
    "#     if \"head\" in name:\n",
    "#         continue\n",
    "#     layer_num = int(name.split(\".\")[2])\n",
    "#     if layer_num <= 20:\n",
    "#         param.requires_grad = False\n",
    "#         continue"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfe71b3a-d359-4340-b5bb-30937f84ab63",
   "metadata": {},
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "420cd6a6-b439-451b-980d-72bc540aba52",
   "metadata": {},
   "source": [
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_trainable_params = count_trainable_parameters(model)\n",
    "print(f\"Number of trainable parameters: {num_trainable_params}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8beff984-4201-4232-a7fc-da7c4a01c8a0",
   "metadata": {},
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='training_log.txt', level=logging.INFO)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff98367e-119c-46af-b76b-5733a4f2d9e1",
   "metadata": {},
   "source": [
    "# eval_set = json.load(open(\"data/eval_set.json\", \"r\"))[:10] # TODO!!!!\n",
    "eval_set = json.load(open(\"data/eval_set.json\", \"r\"))\n",
    "train_set = json.load(open(\"data/train_set.json\", \"r\"))\n",
    "def custom_evaluation(model, epoch, short=True):\n",
    "    if short:\n",
    "        keywords = [e['keyword'] for e in eval_set if e['difficulty'] == \"Easy\"]\n",
    "    else:\n",
    "        keywords = [e['keyword'] for e in eval_set]\n",
    "\n",
    "    games = run_games(\n",
    "        keywords,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        id_eot,\n",
    "        batch_size=15,\n",
    "    )\n",
    "    if not short:\n",
    "        pickle.dump(games, open(f\"full_eval_{epoch}.pkl\", \"wb\"))\n",
    "    return sum([g.win for g in games]) / len(games)\n",
    "\n",
    "def custom_evaluation_on_train(model, n_examples=100):\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    random.shuffle(train_set)\n",
    "    \n",
    "    keywords = [e['keyword'] for e in train_set[:n_examples]]\n",
    "    games = run_games(\n",
    "        keywords,\n",
    "        tokenizer,\n",
    "        model,\n",
    "        id_eot,\n",
    "        batch_size=15,\n",
    "    )\n",
    "    return sum([g.win for g in games]) / len(games)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47b7a336-fab2-4665-883d-606b9cc8c505",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c55f6ab-cfea-4963-9ca9-e183eeefa48d",
   "metadata": {},
   "source": [
    "from trl.trainer import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "data_collator = DataCollatorForCompletionOnlyLM(response_template=\"<|start_header_id|>assistant<|end_header_id|>\", tokenizer=tokenizer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93e92ddb-5a73-4d8c-8c01-f70f5d59c2de",
   "metadata": {},
   "source": [
    "model = model.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc12e4b4-a785-4e25-9abc-4d5d3993928a",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a7960e1-61c6-48ac-b3a2-c8e1e993a3ff",
   "metadata": {},
   "source": [
    "save_epochs = set([0])\n",
    "cumulative_epoch = 0\n",
    "for ds, num_epochs in (\n",
    "    # (ds_basic, 1),\n",
    "    # (ds_hints, 1),\n",
    "    (ds_snap, 1),\n",
    "):\n",
    "    for epoch in range(num_epochs):\n",
    "        training_args = SFTConfig(\n",
    "            output_dir=\"./results\",\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=25,\n",
    "            per_device_eval_batch_size=25,\n",
    "            save_strategy=\"no\",\n",
    "            learning_rate=1e-05,\n",
    "            weight_decay=0.2,\n",
    "            bf16=True,\n",
    "            lr_scheduler_type=\"linear\",\n",
    "            warmup_ratio=0.1,\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=150,\n",
    "            logging_steps=150,\n",
    "            neftune_noise_alpha=None,\n",
    "            max_seq_length=5000,\n",
    "            num_of_sequences=5000,\n",
    "            dataset_text_field=\"texts\",\n",
    "        )\n",
    "\n",
    "        trainer = SFTTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=ds,\n",
    "            eval_dataset=ds_eval,\n",
    "            tokenizer=tokenizer,\n",
    "            data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        train_result = trainer.train()\n",
    "        train_loss = train_result.training_loss\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        \n",
    "        eval_result = trainer.evaluate()\n",
    "        eval_loss = eval_result['eval_loss']\n",
    "        \n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        \n",
    "        eval_metrics = custom_evaluation(model, cumulative_epoch)\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "        \n",
    "        if cumulative_epoch in save_epochs:\n",
    "            # TODO!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            # output_dir = f\"./results/llama_{cumulative_epoch}\"\n",
    "            # os.makedirs(output_dir, exist_ok=True)\n",
    "            # model.save_pretrained(output_dir)\n",
    "            # tokenizer.save_pretrained(output_dir)\n",
    "            eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "            logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "            print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "            eval_metrics_on_train = custom_evaluation_on_train(model)\n",
    "            logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "            print(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "        \n",
    "        print(f\"Finished epoch {cumulative_epoch + 1}\")\n",
    "        cumulative_epoch += 1  # Increment the overall epoch counter"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8462c670-f579-4c79-a640-28651147e059",
   "metadata": {},
   "source": [
    "cumulative_epoch = 100\n",
    "eval_metrics = custom_evaluation(model, cumulative_epoch)\n",
    "logging.info(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "print(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "eval_metrics_on_train = custom_evaluation_on_train(model)\n",
    "logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "print(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "222398fa-68ec-417d-a84c-5afa32a01fc3",
   "metadata": {},
   "source": [
    "# eval_metrics = custom_evaluation(model, cumulative_epoch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8277c19c-c4de-4518-bdf9-fcacab554e21",
   "metadata": {},
   "source": [
    "# eval_metrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "222a254c-c781-482e-9c93-27180f5386f2",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2af16a47-7212-49ee-98a9-3fe2ccb20267",
   "metadata": {},
   "source": [
    "# output_dir = f\"./results/llama_{cumulative_epoch}\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# model.save_pretrained(output_dir)\n",
    "# tokenizer.save_pretrained(output_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2046b48-9c0f-4f63-b5a5-68f36883d9d7",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6929d6b8-e82f-4ccd-ae6e-9c1864a4e611",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "08791ce7-0094-4ce9-b2a1-fb8d420eac87",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2bc9d05b-dbee-4be2-a506-745cd17b00ae",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58e6062d-8ea3-4f83-b821-db91b132d4c8",
   "metadata": {},
   "source": [
    "# eval_metrics = custom_evaluation(model, 111, short=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "476350e1-52ab-4081-b623-9b864dc2aa81",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be2d95f6-b0f8-4e9a-96b9-0d0d49c9ffb1",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ec16dce-c7c5-42e8-8e6c-e867807c5062",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb7f8b67-9e0e-461f-90cf-23ac41143d8e",
   "metadata": {},
   "source": [
    "save_epochs = set([0])\n",
    "cumulative_epoch = 0\n",
    "for ds, num_epochs in (\n",
    "    # (ds_basic, 1),\n",
    "    (ds_hints, 1),\n",
    "    # (ds_snap, 1),\n",
    "):\n",
    "    for epoch in range(num_epochs):\n",
    "        training_args = SFTConfig(\n",
    "            output_dir=\"./results\",\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=25,\n",
    "            per_device_eval_batch_size=25,\n",
    "            save_strategy=\"no\",\n",
    "            learning_rate=1e-05,\n",
    "            weight_decay=0.25,\n",
    "            bf16=True,\n",
    "            lr_scheduler_type=\"linear\",\n",
    "            warmup_ratio=0.1,\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=150,\n",
    "            logging_steps=150,\n",
    "            neftune_noise_alpha=None,\n",
    "            max_seq_length=5000,\n",
    "            num_of_sequences=5000,\n",
    "            dataset_text_field=\"texts\",\n",
    "        )\n",
    "\n",
    "        trainer = SFTTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=ds,\n",
    "            eval_dataset=ds_eval,\n",
    "            tokenizer=tokenizer,\n",
    "            # data_collator=data_collator,\n",
    "        )\n",
    "\n",
    "        train_result = trainer.train()\n",
    "        train_loss = train_result.training_loss\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Train Loss: {train_loss}\")\n",
    "        \n",
    "        eval_result = trainer.evaluate()\n",
    "        eval_loss = eval_result['eval_loss']\n",
    "        \n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Eval Loss: {eval_loss}\")\n",
    "        \n",
    "        eval_metrics = custom_evaluation(model, cumulative_epoch)\n",
    "        logging.info(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "        print(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "        \n",
    "        if cumulative_epoch in save_epochs:\n",
    "            # TODO !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            # output_dir = f\"./results/llama_no_mask_{cumulative_epoch}\"\n",
    "            # os.makedirs(output_dir, exist_ok=True)\n",
    "            # model.save_pretrained(output_dir)\n",
    "            # tokenizer.save_pretrained(output_dir)\n",
    "            eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "            logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "            print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "            eval_metrics_on_train = custom_evaluation_on_train(model)\n",
    "            logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "            print(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "       \n",
    "        print(f\"Finished epoch {cumulative_epoch + 1}\")\n",
    "        cumulative_epoch += 1  # Increment the overall epoch counter"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb203df2-6bc9-492f-920d-7236b4a90424",
   "metadata": {},
   "source": [
    "# eval_metrics = custom_evaluation(model, cumulative_epoch)\n",
    "# logging.info(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "# print(f\"Epoch {cumulative_epoch} - Custom Eval: {eval_metrics}\")\n",
    "# eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "# logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "# print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "# eval_metrics_on_train = custom_evaluation_on_train(model)\n",
    "# logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")\n",
    "# print(f\"Epoch {cumulative_epoch} - Custom Eval (full train): {eval_metrics_on_train}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "919bdc64-9dd4-4a63-ac68-844bd193bf32",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8255dbec-a4dd-4cea-abb7-9550a54de60b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0066d42-a20a-450f-88a4-c2c3ddf0476b",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a8142da-1989-4190-ac8c-87164bd429f9",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7275f18-44bb-4dc7-9de6-7a9dea8ad953",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89cc6161-56ae-490c-86b6-0ff7e4b62adf",
   "metadata": {},
   "source": [
    "output_dir = f\"./results/llama_no_mask_{cumulative_epoch}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "eval_metrics = custom_evaluation(model, cumulative_epoch, short=False)\n",
    "logging.info(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")\n",
    "print(f\"Epoch {cumulative_epoch} - Custom Eval (full): {eval_metrics}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "74303228-a769-459d-a158-6c53b289bd3f",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ba99374-31cf-49d1-9383-6840eed515d5",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "78424d2b-ae79-4d24-b16c-1170cbc9716d",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b579ace-e152-4b94-a042-52893d5e4984",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
